# spark jobs ( subscribe to kafka which is the middle to move data between data sources and consumrs) 

# kafka is good for low-latency data pipelines 

# the spark job will be batch ingestion 
# process the data and then store processed data in cloud storage or send it to downstream systems
# like dashboard) 


